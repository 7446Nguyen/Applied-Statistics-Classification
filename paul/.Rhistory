library(pacman)
p_load(rrcov, MASS, dplyr, purrr, ggplot2, Hmisc, pcaPP, knitr, kableExtra, caret, cluster, robustbase)
df <- read.csv("./modelingKobeData.csv", header=T, sep=",", strip.white=T, stringsAsFactors = F, na.strings=c(""))
df.preds <- read.csv("./predictionKobeData.csv", header=T, sep=",", strip.white=T, stringsAsFactors = F, na.strings=c(""))
library(pacman)
p_load(rrcov, MASS, dplyr, purrr, ggplot2, Hmisc, pcaPP, knitr, kableExtra, caret, cluster, robustbase)
df <- read.csv("./modelingKobeData.csv", header=T, sep=",", strip.white=T, stringsAsFactors = F, na.strings=c(""))
df.preds <- read.csv("./predictionKobeData.csv", header=T, sep=",", strip.white=T, stringsAsFactors = F, na.strings=c(""))
shotsTaken <- data.frame(df$loc_x, df$loc_y, df$shot_distance)
colnames(shotsTaken) <- c("loc_x", "loc_y", "shot_distance")
# simple plot using EVENT_TYPE to colour the dots
ggplot(shotsTaken, aes(x=loc_x, y=loc_y)) +
geom_point(aes(colour = df$shot_type))
df[which(df$loc_y > 300),"shot_type"] <- "3PT Field Goal"
df.preds[which(df.preds$loc_y > 300),"shot_type"] <- "3PT Field Goal"
# Convert the points to integer values since they have integer value in reality
df$shot_type <- ifelse(df$shot_type=="2PT Field Goal", 2, 3)
df.preds$shot_type <- ifelse(df.preds$shot_type=="2PT Field Goal", 2, 3)
badNews <- "Sorry, but your math is off and the transformations were not performed. Please update and try again."
tryCatch(
{
# Convert all integers to numeric and characters to factors with levels:
df <- df %>% mutate_if(is.integer, as.numeric) %>% mutate_if(is.character, as.factor) %>% data.frame()
df <- df %>%
subset(select=-c(team_id, # dropping since this is a uniform distribution of data
team_name, # dropping since this is a uniform distribution of data. Also collinear with team_id
action_type, # dropping this in favor of combined_shot_type
shot_zone_area, # this is ambiguous and less descriptive than geospatial data
shot_zone_basic, # this is ambiguous and less descriptive than geospatial data
shot_zone_range, # this is ambiguous and less descriptive than geospatial data
matchup # removing in favor of opponent; Kobe only played for LAL so that will never change
)
)
# create numeric dataframe for correlation plot
df.numeric <- df %>% keep(is.numeric)
df.preds <- df.preds %>% mutate_if(is.integer, as.numeric) %>% mutate_if(is.character, as.factor) %>% data.frame()
df.preds <- df.preds %>%
subset(select=-c(team_id, # dropping since this is a uniform distribution of data
team_name, # dropping since this is a uniform distribution of data. Also collinear with team_id
action_type, # dropping this in favor of combined_shot_type
shot_zone_area, # this is ambiguous and less descriptive than geospatial data
shot_zone_basic, # this is ambiguous and less descriptive than geospatial data
shot_zone_range, # this is ambiguous and less descriptive than geospatial data
matchup # removing in favor of opponent; Kobe only played for LAL so that will never change
)
)
# create numeric dataframe for correlation plot
df.numeric.preds <- df.preds %>% keep(is.numeric)
},
error = function(e)
{
badNews
}
)
corrplot::corrplot(cor(df.numeric %>% subset(select=-c(shot_made_flag)))
, title = "Correlation among Predictor Variables"
, type = "lower"
, tl.pos = "ld"
, method = "square"
, tl.cex = 0.65
, tl.col = 'red'
, order = "alphabet"
, diag = F
, mar=c(0,0,5,0)
, bg="ivory1"
,tl.srt=.05
)
df <- df %>% subset(select=-c(lat, # dropping lat because it is collinear with loc_y and shot_distance
lon, # dropping lon because it is collinear with loc_x and shot_distance
period, # dropping period in favor of game event id because game event id is more descriptive and continuous
game_id # dropping playoffs for game_id; game ID can capture playoffs seasonally
)
)
df.preds <- df.preds %>% subset(select=-c(lat, # dropping lat because it is collinear with loc_y and shot_distance
lon, # dropping lon because it is collinear with loc_x and shot_distance
period, # dropping period in favor of game event id because game event id is more descriptive and continuous
game_id # dropping playoffs for game_id; game ID can capture playoffs seasonally
)
)
df.numeric <- df %>% keep(is.numeric) %>% mutate_if(is.integer, as.numeric)
df.numeric.preds <- df.preds %>% keep(is.numeric) %>% mutate_if(is.integer, as.numeric)
flattenCorrMatrix <- function(cormatrix, pmatrix) {
ut <- upper.tri(cormatrix)
data.frame(
row = rownames(cormatrix)[row(cormatrix)[ut]],
column = rownames(cormatrix)[col(cormatrix)[ut]],
cor  =(cormatrix)[ut],
p = pmatrix[ut]
)
}
options(scipen=999)
options(max.print=100000)
#See what variables are correlated with eachother, p-values
correlation.matrix <- Hmisc::rcorr(as.matrix(df.numeric), type="pearson")
corDF <- data.frame(flattenCorrMatrix(correlation.matrix$r, correlation.matrix$P))
corDF.ordered <- data.frame(corDF[order(-corDF$cor),])
collinear.correlation <- corDF[which(corDF$cor >= 0.50),]
collinear.correlation <- table(collinear.correlation[order(-collinear.correlation$cor),])
collinear.correlation_Ten <- head(data.frame(collinear.correlation), 10)
colnames(collinear.correlation_Ten) = c("Row", "Column", "Correlation", "p-value")
kable(collinear.correlation_Ten)
kable(collinear.correlation_Ten)
collinear.correlation <- table(collinear.correlation[order(-collinear.correlation$cor),])
collinear.correlation_Ten <- head(data.frame(collinear.correlation), 10)
colnames(collinear.correlation_Ten) = c("Row", "Column", "Correlation", "p-value")
collinear.correlation_Ten <- data.frame(collinear.correlation_Ten)
collinear.correlation_Ten$Correlation <- round(collinear.correlation_Ten$Correlation, digits=3)
collinear.correlation_Ten$Correlation <- round(as.numeric(collinear.correlation_Ten$Correlation), digits=3)
kable(collinear.correlation_Ten)
collinear.correlation_Ten <- head(data.frame(collinear.correlation), 10)
colnames(collinear.correlation_Ten) = c("Row", "Column", "Correlation", "p-value")
collinear.correlation_Ten <- data.frame(collinear.correlation_Ten)
collinear.correlation_Ten$Correlation <- round(as.numeric(collinear.correlation_Ten$Correlation), digits=5)
kable(collinear.correlation_Ten)
collinear.correlation_Ten <- head(data.frame(collinear.correlation), 10)
colnames(collinear.correlation_Ten) = c("Row", "Column", "Correlation", "p-value")
kable(collinear.correlation_Ten)
collinear.correlation_Ten$Correlation <- substring(collinear.correlation_Ten$Correlation, 0,4)
kable(collinear.correlation_Ten)
collinear.correlation_Ten <- head(data.frame(collinear.correlation), 10)
colnames(collinear.correlation_Ten) = c("Row", "Column", "Correlation", "p-value")
kable(collinear.correlation_Ten)
dfTrain <- df[which(!is.na(df$shot_made_flag)),]
prediction.Data <- df[which(is.na(df$shot_made_flag)),]
test_sample_size <- floor(0.75 * nrow(dfTrain))
set.seed(123)
train_ind <- sample(seq_len(nrow(dfTrain)), size = test_sample_size)
subDF.Train <- dfTrain[train_ind, ] #75% training
subDF.Test <- dfTrain[-train_ind, ] # 25% testing
dfTrain.numeric <- df.numeric[which(!is.na(df.numeric$shot_made_flag)),]
prediction.Data.numeric <- df.numeric[which(is.na(df.numeric$shot_made_flag)),]
dfTrain.numeric$shot_made_flag <- as.factor(dfTrain.numeric$shot_made_flag)
dfTrain.numeric$shot_made_flag <- ifelse(dfTrain.numeric$shot_made_flag=="1", "made", "not_made")
dfTrain.numeric <- dfTrain.numeric %>% mutate_if(is.integer, as.numeric) %>% mutate_if(is.character, as.factor) %>% data.frame()
test_sample_size <- floor(0.75 * nrow(dfTrain.numeric))
set.seed(123)
train_ind <- sample(seq_len(nrow(dfTrain.numeric)), size = test_sample_size)
subDF.Train.numeric <- dfTrain.numeric[train_ind, ] #75% training
subDF.Test.numeric <- dfTrain.numeric[-train_ind, ] # 25% testing
Bartlett_ChiSq <- rrcov::Wilks.test(shot_made_flag ~ ., data=dfTrain.numeric, method = "c", approximation = "Bartlett")
# Wilk's Lambda produces significant p-value in Bartlett's test so we need to use a Quadratic Discriminant Analysis instead of Linear
format(round(Bartlett_ChiSq$p.value, 2), nsmall=4)
# Wilks' Lambda plus degrees of freedom used in Bartlett's chi-squared test
WilksDegreesofFreedom <- rbind(as.numeric(paste0(Bartlett_ChiSq$parameter, sep = " ")))
# p-value from Bartlett's test
Bartlett_ChiSq$p.value
Bartletts_p <- format(round(as.numeric(Bartlett_ChiSq$p.value), 2), nsmall=4)
# Because Bartlett's p-value is less than 0.0001 (indicated above), updating to shorter form:
Bartletts_p = ifelse(Bartlett_ChiSq$p.value < 0.0001, "p < 0.0001", Bartlett_ChiSq$p.value)
#Bartletts_p <- "p < 0.0001"
dfBartlett <- data.frame(WilksDegreesofFreedom, Bartlett_ChiSq$wilks, Bartletts_p)
colnames(dfBartlett) <- c("Chi-Square Statistic", "Degrees of Freedom", "Wilks' Lambda", "p-value")
kable(data.frame("Chi-Square Statistic" = dfBartlett$`Chi-Square Statistic`,
"Degrees of Freedom" = dfBartlett$`Degrees of Freedom`,
"Wilks' Lambda" = dfBartlett$`Wilks' Lambda`,
"p-value" = Bartletts_p),
format="markdown", booktabs = T)  %>%
kable_styling(position = "center")
kobe.qda <- qda(shot_made_flag ~ ., CV=T, data=dfTrain.numeric)
data.frame(mean(kobe.qda$posterior[,1]), mean(kobe.qda$posterior[,2]))
shot_made_flagg <- rbind("0", "1")
proportion <- rbind(mean(kobe.qda$posterior[,1]), mean(kobe.qda$posterior[,2]))
table(shot_made_flagg, proportion) # Class Level Information
subDF.Train.numeric$shot_made_flag <- as.factor(subDF.Train.numeric$shot_made_flag)
#subDF.Train.numeric$shot_made_flag <- ifelse(subDF.Train.numeric$shot_made_flag=="1", "made", "not_made")
subDF.Train.numeric <- subDF.Train.numeric %>% mutate_if(is.integer, as.numeric) %>% mutate_if(is.character, as.factor) %>% data.frame()
pred = predict(qda.filtered, newdata=dfTrain.numeric)
train.Control <- caret::trainControl(method = "repeatedcv",
number = 25,
repeats = 5,
summaryFunction = twoClassSummary,
classProbs = T)
# build the model using the 75% partitioned from the internal dataset (the set with all shot_made_flag response results):
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "Spec"
)
test_pred.qda.filtered <- suppressWarnings(predict(qda.filtered, newdata = subDF.Test.numeric))
# build a confusion matrix for internal cross-validation to see performance:
confusion_matrix_results.test <- confusionMatrix(table(test_pred.qda.filtered, subDF.Test.numeric$shot_made_flag))
confusion_matrix_results.test
internal_cv.predicted.qda <- suppressWarnings(predict(qda.filtered, newdata = dfTrain.numeric))
# compare the predicted results to the actual results to make sure model still performs as intended:
confusion_matrix_results.internal <- confusionMatrix(table(internal_cv.predicted.qda, dfTrain.numeric$shot_made_flag))
confusion_matrix_results.internal
misclassification.QDA <- (confusion_matrix_results.internal$table[2,1] + confusion_matrix_results.internal$table[1,2]) / sum(confusion_matrix_results.internal$table)
kable(paste0(round(misclassification.QDA*100, digits=3), "%", sep=""))
pred = predict(qda.filtered, newdata=dfTrain.numeric)
cf = confusionMatrix(table(data=as.numeric(pred>0.5), dfTrain.numeric$shot_made_flag))
pred
train.qda.probs <- predict(qda.filtered)$posterior[, "made"]
predict(qda.filtered)$posterior
predict(qda.filtered)
predict(qda.filtered)$posterior
predict(qda.filtered)$posterior[, "made"]
model.forward.Start <- glm(shot_made_flag~1, family=binomial(link='logit'), data = df)
model.Allvar <- glm(shot_made_flag ~ recId + combined_shot_type + game_event_id + game_id + loc_x + loc_y +
minutes_remaining + season + seconds_remaining + shot_distance + shot_type + game_date +
opponent + shot_id + attendance + arena_temp + avgnoisedb, family=binomial(link='logit'), data = df)
model.Allvar <- glm(shot_made_flag ~ recId + combined_shot_type + game_event_id + playoffs + loc_x + loc_y +
minutes_remaining + season + seconds_remaining + shot_distance + shot_type + game_date +
opponent + shot_id + attendance + arena_temp + avgnoisedb, family=binomial(link='logit'), data = df)
model.Forward <- stepAIC(model.forward.Start, direction = "forward", trace = F, scope = formula(model.Allvar))
summary(model.Forward)
model.Forward$anova
library(ROCR)
install.packages("ROCR", "Metrics")
install.packages("ROCR")
install.packages("Metrics")
library(ROCR)
library(Metrics)
prediction(qda.filtered, subDF.Train.numeric$shot_made_flag)
prediction(internal_cv.predicted.qda, dfTrain.numeric$shot_made_flag)
internal_cv.predicted.qda
dfTrain.numeric$shot_made_flag
dfTrain.numeric$shot_made_flag <- ifelse(dfTrain.numeric$shot_made_flag=="made",1,0)
internal_cv.predicted.qda <- ifelse(internal_cv.predicted.qda=="made",1,0)
AUCpredStep <- prediction(internal_cv.predicted.qda, dfTrain.numeric$shot_made_flag)
perf_step <- performance(AUCpredStep, measure = "tpr", x.measure = "fpr")
plot(perf_step, main = "ROC Curve")
auc <- performance(AUCpredStep, measure = "auc")
auc <- auc@y.values[[1]]
auc
auc
predict(qda.filtered)$posterior[, 1]
qda(shot_made_flag ~ ., CV=T, data=subDF.Train.numeric)
qda.fit <- qda(shot_made_flag ~ ., CV=T, data=subDF.Train.numeric)
pred = predict(qda.fit, newdata=dfTrain.numeric)
predict(qda.fit)$posterior[, "made"]
predict(qda.fit)$posterior[, "made"]
misClassError(trainY, train.qda.probs)
predict(qda.fit)$posterior
?predict
predict(qda.fit, newdata = dfTrain.numeric)$posterior[, 2]
dfTrain.numeric$shot_made_flag <- as.integer(dfTrain.numeric$shot_made_flag)
test.qda.probs <- predict(qda.fit, newdata = dfTrain.numeric)$posterior[, 2]
str(dfTrain.numeric)
predict(qda.fit, newdata = dfTrain.numeric)
suppressWarnings(predict(qda.fit)$posterior[, "made"])
predict(qda.fit)$posterior[, 1]
predict(qda.fit)$posterior[, 0]
predict(qda.fit)$posterior[, "made"]
badNews <- "Sorry, but your math is off and the transformations were not performed. Please update and try again."
tryCatch(
{
predict(qda.fit)$posterior[, "made"]
},
error = function(e)
{
badNews
}
)
badNews <- "Sorry, but your math is off and the transformations were not performed. Please update and try again."
tryCatch(
{
predict(qda.fit)$posterior[, "made"]
},
error = function(e)
{
e
}
)
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "logLoss"
)
print(qda.filtered)
train.Control <- caret::trainControl(method = "repeatedcv",
number = 25,
repeats = 5,
#summaryFunction = twoClassSummary,
summaryFunction = logLoss,
classProbs = T)
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "logLoss"
)
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
#, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "logLoss"
)
train.Control <- caret::trainControl(method = "repeatedcv",
number = 25,
repeats = 5,
summaryFunction = twoClassSummary,
#summaryFunction = logLoss,
classProbs = T)
# build the model using the 75% partitioned from the internal dataset (the set with all shot_made_flag response results):
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "logLoss"
)
train.Control <- caret::trainControl(method = "repeatedcv",
number = 25,
repeats = 5,
#summaryFunction = twoClassSummary,
summaryFunction = mnLogLoss,
classProbs = T)
qda.filtered <- train(shot_made_flag ~ .
, data = subDF.Train.numeric
, method = "qda"
, trControl=train.Control
, preProcess = c("center", "scale", "spatialSign")
#, preProcess = "spatialSign"
, metric = "logLoss"
)
print(qda.filtered)
print(internal_cv.predicted.qda)
